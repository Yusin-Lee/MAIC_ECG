{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"qflruFDST8Zl"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Anaconda\\envs\\tf_keras\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n","c:\\Anaconda\\envs\\tf_keras\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n"," The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n","Some things might work, some things might not.\n","If you were to encounter a bug, do not file an issue.\n","If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n","You can find the compatibility matrix in TensorFlow Addon's readme:\n","https://github.com/tensorflow/addons\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["%pylab is deprecated, use %matplotlib inline and import the required libraries.\n","Populating the interactive namespace from numpy and matplotlib\n"]}],"source":["import numpy as np\n","from matplotlib import pyplot as plt\n","import pandas as pd\n","import pickle\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from tensorflow_addons.optimizers import RectifiedAdam\n","\n","import sys\n","import torch\n","from sklearn.model_selection import train_test_split\n","from network_tools import *\n","from hnet import *\n","from RHCnet_Custom_dataset import CustomDataset, TF_Dataloader, ad_TF_Dataloader_Norm\n","%pylab inline\n","\n","# path to the pre-trained model\n","PRE_TRAINED_MODEL_PATH = './ecg_supervised_416.h5'"]},{"cell_type":"markdown","metadata":{},"source":["# Adult"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"background_save":true},"id":"qlACbe6hsQGo"},"outputs":[],"source":["adult_train = pd.read_csv('./dataset/ECG_adult_age_train_splited.csv')\n","adult_valid = pd.read_csv('./dataset/ECG_adult_age_valid_splited.csv')\n","new_adult_train = pd.read_csv('./dataset/new_train_adult.csv')\n","adult_train_ = pd.concat([adult_train,new_adult_train])\n","adult_train_.reset_index(drop=True,inplace=True)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# For classification Version\n","\n","# sampled_df = adult_train.groupby('seped_AGE').apply(lambda x: x.sample(n = 2000, random_state=42)).reset_index(drop=True)\n","# sampled_df.drop('seped_AGE',axis=1,inplace=True)\n","# adult_train.drop('AGE',axis=1,inplace=True)\n","# adult_train.columns = ['FILENAME','GENDER','AGE']\n","# adult_train['AGE'] =  adult_train['AGE'] - 2\n","\n","# category = 7\n","# im = np.eye(7)\n","# train_label = im[train_label]\n","# valid_label = im[valid_label]"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"background_save":true},"id":"LPuDe_tkZU4c"},"outputs":[],"source":["# adult_file_path = './dataset/ECG_adult_numpy_train/'\n","# adult_train_data, adult_valid_data = train_test_split(adult_train,shuffle=True, random_state=42, test_size=0.2, stratify = adult_train['seped_AGE'])\n","# adult_train_data.drop('seped_AGE',axis=1,inplace=True)\n","# adult_valid_data.drop('seped_AGE',axis=1,inplace=True)\n","# adult_train_data.reset_index(inplace=True,drop=True)\n","# adult_valid_data.reset_index(inplace=True,drop=True)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Torch defualt Dataloader\n","# N * 12 * 5000\n","\n","# adult_train_dataset = CustomDataset(adult_file_path,adult_train_data)\n","# adult_valid_dataset = CustomDataset(adult_file_path,adult_valid_data)\n","# train_adult_loader = torch.utils.data.DataLoader(adult_train_dataset, batch_size = 32, shuffle=False) # len(adult_train_dataset)\n","# valid_adult_loader = torch.utils.data.DataLoader(adult_valid_dataset, batch_size = 32, shuffle=False) # len(adult_valid_dataset)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Tensorflow default Dataloader\n","\n","# train_adult_loader = TF_Dataloader(adult_file_path, adult_train_data, 32, shuffle=True)\n","# valid_adult_loader = TF_Dataloader(adult_file_path, adult_valid_data, 32, shuffle=False)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Tensorflow Dataloader + ECG data normalized by mean and std\n","adult_file_path = './dataset/numpy_joined/'\n","train_adult_loader = ad_TF_Dataloader_Norm(adult_file_path, adult_train_, 32, shuffle=True)\n","valid_adult_loader = ad_TF_Dataloader_Norm(adult_file_path, adult_valid, 32, shuffle=False)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":15109,"status":"ok","timestamp":1695183436493,"user":{"displayName":"Yusin Lee","userId":"01807844691984934210"},"user_tz":-540},"id":"FF-OafWBqZpP"},"outputs":[],"source":["# (N*12*5000) -> (N*5000*12)\n","\n","# train_batch = next(iter(train_adult_loader))\n","# valid_batch = next(iter(valid_adult_loader))\n","# train_input = train_batch[0].view(-1,12,5000).transpose(1,2).numpy()\n","# train_label = train_batch[2].numpy()\n","# valid_input = valid_batch[0].view(-1,12,5000).transpose(1,2).numpy()\n","# valid_label = valid_batch[2].numpy()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["with tf.device('/device:CPU:0'):\n","    pre_trained_model = load_pretrained_model()\n","    latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n","    adult_model = AppendNet(latent)\n","    adult_model.build((None,5000,12))\n","optimizer = tf.keras.optimizers.Adam(learning_rate = 3e-4)\n","loss_fn = tf.keras.losses.MeanSquaredError()\n","epochs=20\n","with tf.device('/device:CPU:0'):\n","    adult_model.compile(optimizer, loss_fn, metrics = 'mae')\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath='./ckp/adult_weight_2',\n","    save_weights_only=False,\n","    monitor='val_loss',\n","    mode='min',\n","    save_best_only=True)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","3109/3109 [==============================] - ETA: 0s - loss: 487.9904 - mae: 16.5282"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\adult_weight_2\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\adult_weight_2\\assets\n"]},{"name":"stdout","output_type":"stream","text":["3109/3109 [==============================] - 826s 265ms/step - loss: 487.9904 - mae: 16.5282 - val_loss: 151.0527 - val_mae: 10.0767\n","Epoch 2/20\n","3109/3109 [==============================] - ETA: 0s - loss: 365.6077 - mae: 14.8490"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\adult_weight_2\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\adult_weight_2\\assets\n"]},{"name":"stdout","output_type":"stream","text":["3109/3109 [==============================] - 817s 263ms/step - loss: 365.6077 - mae: 14.8490 - val_loss: 127.3559 - val_mae: 9.0707\n","Epoch 3/20\n","3109/3109 [==============================] - 819s 263ms/step - loss: 322.8654 - mae: 14.3209 - val_loss: 154.7903 - val_mae: 10.1319\n","Epoch 4/20\n","3109/3109 [==============================] - 823s 265ms/step - loss: 1160.8406 - mae: 14.1888 - val_loss: 164.5825 - val_mae: 10.4827\n","Epoch 5/20\n","3109/3109 [==============================] - ETA: 0s - loss: 303.5446 - mae: 13.8757"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\adult_weight_2\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\adult_weight_2\\assets\n"]},{"name":"stdout","output_type":"stream","text":["3109/3109 [==============================] - 824s 265ms/step - loss: 303.5446 - mae: 13.8757 - val_loss: 114.5196 - val_mae: 8.4184\n","Epoch 6/20\n","3109/3109 [==============================] - 843s 271ms/step - loss: 293.4391 - mae: 13.3655 - val_loss: 119.4190 - val_mae: 8.6877\n","Epoch 7/20\n","3109/3109 [==============================] - 844s 272ms/step - loss: 269.1846 - mae: 13.0680 - val_loss: 119.5230 - val_mae: 8.7598\n","Epoch 8/20\n","3109/3109 [==============================] - ETA: 0s - loss: 253.4779 - mae: 12.6243"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\adult_weight_2\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\adult_weight_2\\assets\n"]},{"name":"stdout","output_type":"stream","text":["3109/3109 [==============================] - 854s 274ms/step - loss: 253.4779 - mae: 12.6243 - val_loss: 105.6816 - val_mae: 8.1222\n","Epoch 9/20\n","3109/3109 [==============================] - 843s 271ms/step - loss: 238.0045 - mae: 12.2639 - val_loss: 107.0595 - val_mae: 8.0055\n","Epoch 10/20\n","3109/3109 [==============================] - 843s 271ms/step - loss: 227.0811 - mae: 11.9484 - val_loss: 108.1722 - val_mae: 8.3097\n","Epoch 11/20\n","3109/3109 [==============================] - 854s 275ms/step - loss: 220.1428 - mae: 11.7507 - val_loss: 112.7136 - val_mae: 8.5215\n","Epoch 12/20\n","3109/3109 [==============================] - ETA: 0s - loss: 210.2794 - mae: 11.5114"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\adult_weight_2\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\adult_weight_2\\assets\n"]},{"name":"stdout","output_type":"stream","text":["3109/3109 [==============================] - 853s 274ms/step - loss: 210.2794 - mae: 11.5114 - val_loss: 98.3377 - val_mae: 7.8057\n","Epoch 13/20\n","3109/3109 [==============================] - 849s 273ms/step - loss: 215.8323 - mae: 11.5153 - val_loss: 110.2821 - val_mae: 8.4214\n","Epoch 14/20\n","3109/3109 [==============================] - 855s 275ms/step - loss: 205.1176 - mae: 11.3656 - val_loss: 101.5441 - val_mae: 8.0150\n","Epoch 15/20\n","3109/3109 [==============================] - 852s 274ms/step - loss: 200.7386 - mae: 11.2339 - val_loss: 105.2060 - val_mae: 8.2083\n","Epoch 16/20\n","3109/3109 [==============================] - 884s 284ms/step - loss: 196.7516 - mae: 11.1480 - val_loss: 104.6786 - val_mae: 8.2020\n","Epoch 17/20\n","3109/3109 [==============================] - ETA: 0s - loss: 192.1330 - mae: 11.0146"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\adult_weight_2\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\adult_weight_2\\assets\n"]},{"name":"stdout","output_type":"stream","text":["3109/3109 [==============================] - 885s 284ms/step - loss: 192.1330 - mae: 11.0146 - val_loss: 93.8927 - val_mae: 7.6332\n","Epoch 18/20\n","3109/3109 [==============================] - ETA: 0s - loss: 190.8719 - mae: 10.9813"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\adult_weight_2\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\adult_weight_2\\assets\n"]},{"name":"stdout","output_type":"stream","text":["3109/3109 [==============================] - 899s 289ms/step - loss: 190.8719 - mae: 10.9813 - val_loss: 93.0149 - val_mae: 7.6139\n","Epoch 19/20\n","3109/3109 [==============================] - 897s 288ms/step - loss: 193.8441 - mae: 10.9154 - val_loss: 94.3434 - val_mae: 7.6724\n","Epoch 20/20\n","3109/3109 [==============================] - 904s 291ms/step - loss: 183.0306 - mae: 10.7113 - val_loss: 95.7748 - val_mae: 7.7481\n"]}],"source":["with tf.device('/device:CPU:0'):\n","    adult_model.fit(train_adult_loader, batch_size=32, epochs=epochs, validation_data=valid_adult_loader, callbacks=[model_checkpoint_callback],workers=4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["110/110 [==============================] - 6s 51ms/step\n"]}],"source":["# output = adult_model.predict(valid_input)\n","# output = output.flatten()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["8.897496129202317"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# from sklearn.metrics import mean_absolute_error\n","# mean_absolute_error(output,valid_label)"]},{"cell_type":"markdown","metadata":{},"source":["# Child"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["child_train = pd.read_csv('./dataset/ECG_child_age_train_splited.csv')\n","child_valid = pd.read_csv('./dataset/ECG_child_age_valid_splited.csv')\n","new_train_child = pd.read_csv('./dataset/new_train_child.csv')\n","new_valid_child = pd.read_csv('./dataset/new_valid_child.csv')\n","child_train_ = pd.concat([child_train,new_train_child])\n","child_valid_ = pd.concat([child_valid,new_valid_child])\n","child_train_.reset_index(drop=True,inplace=True)\n","child_valid_.reset_index(drop=True,inplace=True)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Tensorflow Dataloader + ECG data normalized by mean and std\n","child_file_path = './dataset/numpy_joined/'\n","train_child_loader = ad_TF_Dataloader_Norm(child_file_path, child_train_, 32, shuffle=True)\n","valid_child_loader = ad_TF_Dataloader_Norm(child_file_path, child_valid_, 32, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# train_batch = next(iter(train_child_loader))\n","# valid_batch = next(iter(valid_child_loader))\n","# train_input = train_batch[0].view(-1,12,5000).transpose(1,2).numpy()\n","# train_label = train_batch[2].numpy()\n","# valid_input = valid_batch[0].view(-1,12,5000).transpose(1,2).numpy()\n","# valid_label = valid_batch[2].numpy()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["with tf.device('/device:CPU:0'):\n","    pre_trained_model = load_pretrained_model()\n","    latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n","    child_model = AppendNet(latent)\n","    child_model.build((None,5000,12))\n","optimizer = tf.keras.optimizers.Adam(learning_rate = 3e-4)\n","loss_fn = tf.keras.losses.MeanSquaredError()\n","epochs=10\n","with tf.device('/device:CPU:0'):\n","    child_model.compile(optimizer, loss_fn, metrics = 'mae')\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath='./ckp/child_weight',\n","    save_weights_only=False,\n","    monitor='val_loss',\n","    mode='min',\n","    save_best_only=True)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","260/260 [==============================] - ETA: 0s - loss: 15.4189 - mae: 2.4982"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\child_weight\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\child_weight\\assets\n"]},{"name":"stdout","output_type":"stream","text":["260/260 [==============================] - 85s 322ms/step - loss: 15.4189 - mae: 2.4982 - val_loss: 33.0917 - val_mae: 3.6696\n","Epoch 2/10\n","260/260 [==============================] - ETA: 0s - loss: 12.7268 - mae: 2.1737"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\child_weight\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\child_weight\\assets\n"]},{"name":"stdout","output_type":"stream","text":["260/260 [==============================] - 79s 305ms/step - loss: 12.7268 - mae: 2.1737 - val_loss: 28.3920 - val_mae: 3.3661\n","Epoch 3/10\n","260/260 [==============================] - ETA: 0s - loss: 12.1841 - mae: 2.0952"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\child_weight\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\child_weight\\assets\n"]},{"name":"stdout","output_type":"stream","text":["260/260 [==============================] - 82s 315ms/step - loss: 12.1841 - mae: 2.0952 - val_loss: 24.0742 - val_mae: 3.1543\n","Epoch 4/10\n","260/260 [==============================] - ETA: 0s - loss: 11.5216 - mae: 2.0297"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\child_weight\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\child_weight\\assets\n"]},{"name":"stdout","output_type":"stream","text":["260/260 [==============================] - 82s 313ms/step - loss: 11.5216 - mae: 2.0297 - val_loss: 23.5413 - val_mae: 3.2160\n","Epoch 5/10\n","260/260 [==============================] - 78s 299ms/step - loss: 10.3626 - mae: 1.9102 - val_loss: 27.6338 - val_mae: 3.2723\n","Epoch 6/10\n","260/260 [==============================] - ETA: 0s - loss: 9.8788 - mae: 1.8505"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\child_weight\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\child_weight\\assets\n"]},{"name":"stdout","output_type":"stream","text":["260/260 [==============================] - 83s 318ms/step - loss: 9.8788 - mae: 1.8505 - val_loss: 23.0089 - val_mae: 3.0183\n","Epoch 7/10\n","260/260 [==============================] - ETA: 0s - loss: 8.7402 - mae: 1.7586"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\child_weight\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./ckp\\child_weight\\assets\n"]},{"name":"stdout","output_type":"stream","text":["260/260 [==============================] - 82s 316ms/step - loss: 8.7402 - mae: 1.7586 - val_loss: 20.8285 - val_mae: 2.8560\n","Epoch 8/10\n","260/260 [==============================] - 78s 300ms/step - loss: 7.6336 - mae: 1.6665 - val_loss: 23.6891 - val_mae: 2.9927\n","Epoch 9/10\n","260/260 [==============================] - 77s 298ms/step - loss: 6.4550 - mae: 1.5521 - val_loss: 21.0429 - val_mae: 3.1030\n","Epoch 10/10\n","260/260 [==============================] - 78s 301ms/step - loss: 5.5542 - mae: 1.4653 - val_loss: 25.0300 - val_mae: 3.0661\n"]}],"source":["with tf.device('/device:CPU:0'):\n","    child_model.fit(train_child_loader, batch_size=32, epochs=epochs, validation_data=valid_child_loader, callbacks=[model_checkpoint_callback],workers=4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 1s 51ms/step\n"]}],"source":["# output = child_model.predict(valid_input)\n","# output = output.flatten()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["0.806895284435895"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["# from sklearn.metrics import mean_absolute_error\n","# mean_absolute_error(output,valid_label)"]},{"cell_type":"markdown","metadata":{},"source":["# inference"]},{"cell_type":"markdown","metadata":{},"source":["# Load Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["submission = pd.read_csv('./dataset/submission.csv')\n","adult_file_path = './dataset/ECG_adult_numpy_valid/'\n","child_file_path = './dataset/ECG_child_numpy_valid/'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\SNUH벤처\\AppData\\Local\\Temp\\ipykernel_18120\\4184683789.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  child_df.drop('gap', inplace=True, axis= 1)\n","C:\\Users\\SNUH벤처\\AppData\\Local\\Temp\\ipykernel_18120\\4184683789.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  adult_df.drop('gap', inplace=True, axis= 1)\n"]}],"source":["submission['gap'] = submission['FILENAME'].apply(lambda x : x[4:9])\n","child_df = submission[submission['gap'] == 'child']\n","adult_df = submission[submission['gap'] == 'adult']\n","child_df.drop('gap', inplace=True, axis= 1)\n","adult_df.drop('gap', inplace=True, axis= 1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["adult_dataset = TestDataset(adult_file_path,adult_df)\n","child_dataset = TestDataset(child_file_path,child_df)\n","adult_loader = torch.utils.data.DataLoader(adult_dataset, batch_size = len(adult_dataset), shuffle=False)\n","child_loader = torch.utils.data.DataLoader(child_dataset, batch_size = len(child_dataset), shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["(60000,)"]},"metadata":{},"output_type":"display_data"}],"source":["adult_batch = next(iter(adult_loader))\n","child_batch = next(iter(child_loader))\n","adult_input = adult_batch[0].view(-1,12,5000).transpose(1,2).numpy()\n","child_input = child_batch[0].view(-1,12,5000).transpose(1,2).numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNdtMVkOIiBSJVkQC8MKAVR","mount_file_id":"1Cxorz-Jtfl-eTgQuOnFgRM8LGRioDy8O","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":0}
